== [[StreamingRelationV2]] StreamingRelationV2 Leaf Logical Operator

`StreamingRelationV2` is a `MultiInstanceRelation` leaf logical operator that is used to represent <<spark-sql-streaming-MicroBatchReadSupport.adoc#, MicroBatchReadSupport>> or <<spark-sql-streaming-ContinuousReadSupport.adoc#, ContinuousReadSupport>> streaming data sources in a logical plan of a streaming query.

NOTE: Find out more on leaf logical operators in https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-LogicalPlan-LeafNode.html[LeafNode — Base Logical Operator with No Child Operators and Optional Statistics] section in https://bit.ly/mastering-spark-sql[The Internals of Spark SQL] book.

`StreamingRelationV2` is <<creating-instance, created>> when:

* <<spark-sql-streaming-ContinuousMemoryStream.adoc#, ContinuousMemoryStream>> is created

* `DataStreamReader` is requested to <<spark-sql-streaming-DataStreamReader.adoc#load, create a streaming query>> for a <<spark-sql-streaming-MicroBatchReadSupport.adoc#, MicroBatchReadSupport>> or a <<spark-sql-streaming-ContinuousReadSupport.adoc#, ContinuousReadSupport>> data source

`StreamingRelationV2` is resolved (_replaced_) to the following leaf logical operators:

* <<spark-sql-streaming-ContinuousExecutionRelation.adoc#, ContinuousExecutionRelation>> when `ContinuousExecution` is requested for the <<spark-sql-streaming-ContinuousExecution.adoc#logicalPlan, analyzed logical plan>>

* <<spark-sql-streaming-StreamingExecutionRelation.adoc#, StreamingExecutionRelation>> when `MicroBatchExecution` is requested for the <<spark-sql-streaming-MicroBatchExecution.adoc#logicalPlan, analyzed logical plan>>

=== [[creating-instance]] Creating StreamingRelationV2 Instance

`StreamingRelationV2` takes the following to be created:

* [[dataSource]] `DataSourceV2`
* [[sourceName]] Name of the data source
* [[extraOptions]] Options (`Map[String, String]`)
* [[output]] Output attributes (`Seq[Attribute]`)
* [[v1Relation]] Optional <<spark-sql-streaming-StreamingRelation.adoc#, StreamingRelation>>
* [[session]] `SparkSession`
