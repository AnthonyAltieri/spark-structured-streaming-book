== [[HDFSBackedStateStore]] HDFSBackedStateStore -- State Store on HDFS-Compatible File System

`HDFSBackedStateStore` is a link:spark-sql-streaming-StateStore.adoc[StateStore] that uses a HDFS-compatible file system for versioned state persistence.

`HDFSBackedStateStore` is created exclusively when `HDFSBackedStateStoreProvider` <<getStore, is requested for a state store>> (which is when...FIXME).

`HDFSBackedStateStore` can be in the following <<state, states>>:

* `UPDATING`
* `COMMITTED`
* `ABORTED`

[[toString]]
When requested for the string identifier, `HDFSBackedStateStore`...FIXME

[[internal-registries]]
.HDFSBackedStateStore's Internal Registries
[cols="1m,2",options="header",width="100%"]
|===
| Name
| Description

| compressedStream
a| [[compressedStream]]

[source, scala]
----
compressedStream: DataOutputStream
----

The compressed Java https://docs.oracle.com/javase/8/docs/api/java/io/DataOutputStream.html[DataOutputStream] for the <<deltaFileStream, deltaFileStream>>

| deltaFileStream
a| [[deltaFileStream]]

[source, scala]
----
deltaFileStream: CheckpointFileManager.CancellableFSDataOutputStream
----

| finalDeltaFile
a| [[finalDeltaFile]]

[source, scala]
----
finalDeltaFile: Path
----

The Hadoop https://hadoop.apache.org/docs/r2.7.3/api/org/apache/hadoop/fs/Path.html[Path] of the <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#deltaFile, deltaFile>> for the <<newVersion, version>>

| newVersion
a| [[newVersion]]

[source, scala]
----
newVersion: Long
----

Used exclusively when `HDFSBackedStateStore` is requested for the <<finalDeltaFile, finalDeltaFile>>, to <<commit, commit>> and <<abort, abort>>

| state
| [[state]]

| tempDeltaFile
| [[tempDeltaFile]]

| tempDeltaFileStream
| [[tempDeltaFileStream]]
|===

[[logging]]
[TIP]
====
`HDFSBackedStateStore` is an internal class of <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#, HDFSBackedStateStoreProvider>> and uses its <<spark-sql-streaming-HDFSBackedStateStoreProvider.adoc#logging, logger>>.
====

=== [[writeUpdateToDeltaFile]] `writeUpdateToDeltaFile` Internal Method

[source, scala]
----
writeUpdateToDeltaFile(
  output: DataOutputStream,
  key: UnsafeRow,
  value: UnsafeRow): Unit
----

CAUTION: FIXME

=== [[put]] `put` Method

[source, scala]
----
put(key: UnsafeRow, value: UnsafeRow): Unit
----

NOTE: `put` is a part of link:spark-sql-streaming-StateStore.adoc#put[StateStore Contract] to...FIXME

`put` stores the copies of the key and value in <<mapToUpdate, mapToUpdate>> internal registry followed by <<writeUpdateToDeltaFile, writing them to a delta file>> (using <<tempDeltaFileStream, tempDeltaFileStream>>).

[NOTE]
====
`put` can only be used when `HDFSBackedStateStore` is in `UPDATING` state and reports a `IllegalStateException` otherwise.

```
Cannot put after already committed or aborted
```
====

=== [[commit]] Committing State Changes -- `commit` Method

[source, scala]
----
commit(): Long
----

NOTE: `commit` is part of the <<spark-sql-streaming-StateStore.adoc#commit, StateStore Contract>> to commit state changes.

`commit` firstly <<commitUpdates, commitUpdates>> (with the <<newVersion, newVersion>>, the <<mapToUpdate, mapToUpdate>> and the <<compressedStream, compressed stream>>).

`commit` sets the state to `COMMITTED`.

`commit` prints out the following INFO message to the logs:

```
Committed version [newVersion] for [this] to file [finalDeltaFile]
```

`commit` returns a <<newVersion, newVersion>>.

`commit` throws a `IllegalStateException` when executed in any state but `UPDATING` state:

```
Cannot commit after already committed or aborted
```

`commit` throws a `IllegalStateException` for any `NonFatal` exception:

```
Error committing version [newVersion] into [this]
```

=== [[creating-instance]] Creating HDFSBackedStateStore Instance

`HDFSBackedStateStore` takes the following when created:

* [[version]] Version
* [[mapToUpdate]] Key-value registry of `UnsafeRows` (as Java's https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html[java.util.concurrent.ConcurrentHashMap])

`HDFSBackedStateStore` initializes the <<internal-registries, internal registries and counters>>.

=== [[abort]] Aborting State Changes -- `abort` Method

[source, scala]
----
abort(): Unit
----

NOTE: `abort` is part of the <<spark-sql-streaming-StateStore.adoc#abort, StateStore Contract>> to abort the state changes.

`abort`...FIXME

=== [[commitUpdates]] `commitUpdates` Internal Method

[source, scala]
----
commitUpdates(newVersion: Long, map: MapType, output: DataOutputStream): Unit
----

`commitUpdates`...FIXME

NOTE: `commitUpdates` is used exclusively when `HDFSBackedStateStore` is requested to <<commit, commit state changes>>.
